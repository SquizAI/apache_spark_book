# Glossary of Apache Spark Terms

This glossary provides definitions for key terms and concepts related to Apache Spark used throughout this book. For detailed explanations, refer to the relevant chapters.

*   Accumulators
*   Actions
*   `agg()`
*   `aggregate()`
*   `aggregateByKey()`
*   `aggregateMessages`
*   Alternating Least Squares (ALS)
*   Apache Spark
*   Apache Spark Installation
*   Application Execution
*   Avro
*   Batch Processing
*   Big Data
*   Big Data Analytics
*   Broadcast Variables
*   Bucketizer
*   `cache()`
*   `cartesian()`
*   Catalyst Optimizer
*   Caching
*   Checkpointing
*   Classification
*   Cluster Computing
*   Cluster Manager (Standalone, YARN, Mesos, Kubernetes)
*   `coalesce`
*   `cogroup()`
*   `col()`
*   `collect()`
*   Collaborative Filtering
*   Columnar Processing
*   Connected Components
*   `count()`
*   `countByWindow()`
*   CountVectorizer
*   Creating RDDs
*   `CrossValidator`
*   CSV
*   Custom Partitioner
*   DAG (Directed Acyclic Graph)
*   DAG Scheduler
*   DAG Visualization
*   DataFrame API
*   DataFrame-based Graphs
*   `DataFrameReader`
*   `DataFrameWriter`
*   DataFrames
*   Data Partitioning
*   Data Pipelines
*   Data Skew
*   Data Sources API
*   Dataset API
*   Datasets
*   Decision Trees
*   `DenseVector`
*   Directed Acyclic Graph (DAG)
*   `distinct()`
*   Distributed Computing
*   Distributed Graph Processing
*   Download Spark
*   Driver Program
*   DStream (Discretized Stream)
*   `EdgeRDD`
*   ElementwiseProduct
*   Encoders
*   Estimator
*   ETL (Extract, Transform, Load)
*   Evaluator
*   Event Timeline
*   Execution Memory
*   Executors
*   Fault Tolerance
*   Feature Engineering
*   Feature Extraction
*   Feature Selection
*   Feature Transformation
*   File Streams
*   `filter()`
*   `first()`
*   First Spark Application
*   `flatMap()`
*   Flume
*   `fold()`
*   `foreach()`
*   `foreachRDD()`
*   Garbage Collection (GC) Tuning
*   Generalized Linear Regression (GLR)
*   `Graph[VD, ED]`
*   Graph Algorithms
*   GraphFrames
*   Graph Operators
*   Graph Processing
*   Graph Theory
*   GraphX
*   `groupBy()`
*   `groupByKey()`
*   `groupByKey` vs `reduceByKey`
*   Gradient-Boosted Trees (GBTs)
*   Hadoop
*   HashPartitioner
*   Hive Tables
*   Hyperparameter Tuning
*   Immutability
*   IndexToString
*   In-Memory Processing
*   `intersection()`
*   Java
*   Java Development Kit (JDK)
*   JDBC
*   Job
*   `join()`
*   `joinVertices`
*   JSON
*   K-Means
*   Kafka
*   Key-Value RDDs (Pair RDDs)
*   Kinesis
*   Kryo Serialization
*   `LabeledPoint`
*   Large-Scale Data Processing
*   Latent Dirichlet Allocation (LDA)
*   Linear Regression
*   Loading Models
*   Local Mode
*   Logistic Regression
*   Machine Learning
*   Machine Learning Applications
*   `map()`
*   `mapEdges`
*   `mapTriplets`
*   `mapVertices`
*   `mapWithState`
*   MapReduce
*   `mask`
*   Mesos
*   Micro-batching
*   MLlib
*   MinMaxScaler
*   Model Evaluation
*   Model Persistence
*   Model Training
*   Motif Finding
*   Multilayer Perceptron
*   Naive Bayes
*   Narrow Transformations
*   Normalizer
*   Off-Heap Memory
*   On-Heap Memory
*   OneHotEncoder
*   ORC
*   `orderBy()`
*   Output Operations (`print()`, `saveAsTextFiles()`, `foreachRDD()`)
*   PageRank
*   `parallelize()`
*   Parameter
*   Parquet
*   PCA (Principal Component Analysis)
*   `persist()`
*   Persistence
*   Pipeline
*   Predicate Pushdown
*   Pregel API
*   Property Graph
*   `pyspark`
*   Python
*   R
*   Random Forests
*   RangePartitioner
*   RDD Actions
*   RDD Lineage
*   RDD Partitioning
*   RDD Persistence
*   RDD to DataFrame / DataFrame to RDD
*   RDD Transformations
*   Real-Time Analytics
*   Real-time Processing
*   `reduce()`
*   `reduceByKey()`
*   `reduceByKeyAndWindow()`
*   Regression
*   `repartition`
*   Resilient Distributed Datasets (RDDs)
*   Saving Models
*   Scala
*   Schema
*   Semi-Structured Data
*   Shared Variables
*   Shuffle Operations
*   Shortest Paths
*   Sliding Window
*   Spark Architecture
*   Spark Case Studies
*   Spark Configuration
*   `SparkContext`
*   Spark Memory Management
*   Spark MLlib
*   Spark Optimization
*   Spark Optimizations
*   Spark Performance Tuning
*   `spark-defaults.conf`
*   `spark-env.sh`
*   `SPARK_HOME`
*   `spark.ml`
*   `spark.mllib`
*   `spark.sql()`
*   `spark.speculation`
*   Spark RDD
*   `spark-shell`
*   Spark Setup
*   `SparkSession`
*   Spark SQL
*   Spark SQL for Graphs
*   Spark SQL with DStreams
*   Spark Streaming
*   `spark-submit`
*   Spark UI
*   `SparseVector`
*   Speculative Execution
*   SQL Queries
*   SQLTransformer
*   StandardScaler
*   Stages
*   Standalone Cluster Mode
*   Stateless Transformations (`map`, `filter`, `flatMap`, `reduceByKey`)
*   Stateful Transformations (`updateStateByKey`, `mapWithState`)
*   Storage Levels (`StorageLevel`)
*   Storage Memory
*   Stragglers
*   Stream Sources
*   `StreamingContext`
*   StringIndexer
*   Structured Data
*   Structured Streaming
*   `subgraph`
*   `take()`
*   `takeSample()`
*   Task Metrics
*   Task Scheduler
*   Tasks
*   TCP Sockets
*   `textFile()`
*   TF-IDF
*   `TrainValidationSplit`
*   Transformer
*   Transformations
*   Triangle Counting
*   Tumbling Window
*   Tungsten Execution Engine
*   Type Safety
*   UDAF (User-Defined Aggregate Functions)
*   UDF (User-Defined Functions)
*   Unified Memory Model
*   `union()`
*   `updateStateByKey`
*   `Vector`
*   VectorAssembler
*   `VertexRDD`
*   `where()`
*   Wide Transformations
*   `window()`
*   `withColumn()`
*   Word Count
*   Word2Vec
*   Worker Node
*   YARN (Yet Another Resource Negotiator)
